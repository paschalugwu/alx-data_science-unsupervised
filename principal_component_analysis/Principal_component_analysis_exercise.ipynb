{"cells":[{"cell_type":"markdown","metadata":{"id":"Ee-v8I_P8rfp"},"source":["<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n","<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Exercise.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n","</div>\n","\n","# Exercise: Principal component analysis\n","© ExploreAI Academy\n","\n","In this exercise, we apply PCA to a dataset, evaluate the cumulative variance explained, and determine the appropriate number of components to retain."]},{"cell_type":"markdown","metadata":{"id":"ITqrvAqq8xSC"},"source":["## Learning objectives\n","\n","By the end of this train, you should be able to:\n","* Apply PCA to reduce a dataset’s dimensionality.\n","* Evaluate the cumulative variance explained by each principal component.\n","* Determine the number of components needed to capture at least 85% of the variance."]},{"cell_type":"markdown","metadata":{"id":"f-cEKq-HHJTM"},"source":["## Overview\n","\n","The Digits dataset consists of 1,797 images of handwritten digits, each represented by a 64-dimensional feature vector. The dataset's high dimensionality can pose challenges when visualising and exploring it and could also lead to model complexity.\n","\n","In this exercise, we apply PCA to the Digits dataset and evaluate its ability to reduce the dataset's dimensionality while retaining valuable information."]},{"cell_type":"markdown","metadata":{"id":"lUk_CHpbHJTP"},"source":["## Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3265,"status":"ok","timestamp":1716647211566,"user":{"displayName":"Paschal Ugwu","userId":"02920440952136523881"},"user_tz":-60},"id":"uA1FT6ZdHJTQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"TIvOimJdHJTU"},"source":["## Load and prepare dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1094,"status":"ok","timestamp":1716647240688,"user":{"displayName":"Paschal Ugwu","userId":"02920440952136523881"},"user_tz":-60},"id":"6z5Vzbq9HJTV"},"outputs":[],"source":["# Load the dataset\n","digits = load_digits()\n","X = digits.data\n","y = digits.target\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"]},{"cell_type":"markdown","metadata":{"id":"91Inid-EHJTY"},"source":["## Exercises"]},{"cell_type":"markdown","metadata":{"id":"3CoW1rcYHJTZ"},"source":["### Exercise 1\n","\n","To reduce the dataset's dimensionality, let's transform the standardised dataset by applying PCA."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716647445674,"user":{"displayName":"Paschal Ugwu","userId":"02920440952136523881"},"user_tz":-60},"id":"RvWrAtiWHJTb"},"outputs":[],"source":["# Apply PCA\n","pca = PCA()\n","X_pca = pca.fit_transform(X_scaled)"]},{"cell_type":"markdown","metadata":{"id":"Z7Dfr5hjHJTd"},"source":["### Exercise 2\n","\n","To understand which components carry the most information, we can assess how much of the dataset's variance is captured by each principal component.\n","\n","Compute and print the `Explained Variance Ratio` for each principal component formatted to four decimal places."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1716647970312,"user":{"displayName":"Paschal Ugwu","userId":"02920440952136523881"},"user_tz":-60},"id":"a5qRY3xnHJTe","outputId":"99eed76d-1bad-4fda-8e87-4ecec44c9e94"},"outputs":[{"name":"stdout","output_type":"stream","text":["PC1: Explained Variance = 0.1203\n","PC2: Explained Variance = 0.0956\n","PC3: Explained Variance = 0.0844\n","PC4: Explained Variance = 0.0650\n","PC5: Explained Variance = 0.0486\n","PC6: Explained Variance = 0.0421\n","PC7: Explained Variance = 0.0394\n","PC8: Explained Variance = 0.0339\n","PC9: Explained Variance = 0.0300\n","PC10: Explained Variance = 0.0293\n","PC11: Explained Variance = 0.0278\n","PC12: Explained Variance = 0.0258\n","PC13: Explained Variance = 0.0228\n","PC14: Explained Variance = 0.0223\n","PC15: Explained Variance = 0.0217\n","PC16: Explained Variance = 0.0191\n","PC17: Explained Variance = 0.0178\n","PC18: Explained Variance = 0.0164\n","PC19: Explained Variance = 0.0160\n","PC20: Explained Variance = 0.0149\n","PC21: Explained Variance = 0.0135\n","PC22: Explained Variance = 0.0127\n","PC23: Explained Variance = 0.0117\n","PC24: Explained Variance = 0.0106\n","PC25: Explained Variance = 0.0098\n","PC26: Explained Variance = 0.0094\n","PC27: Explained Variance = 0.0086\n","PC28: Explained Variance = 0.0084\n","PC29: Explained Variance = 0.0080\n","PC30: Explained Variance = 0.0075\n","PC31: Explained Variance = 0.0073\n","PC32: Explained Variance = 0.0069\n","PC33: Explained Variance = 0.0065\n","PC34: Explained Variance = 0.0064\n","PC35: Explained Variance = 0.0059\n","PC36: Explained Variance = 0.0057\n","PC37: Explained Variance = 0.0052\n","PC38: Explained Variance = 0.0048\n","PC39: Explained Variance = 0.0045\n","PC40: Explained Variance = 0.0042\n","PC41: Explained Variance = 0.0041\n","PC42: Explained Variance = 0.0040\n","PC43: Explained Variance = 0.0036\n","PC44: Explained Variance = 0.0034\n","PC45: Explained Variance = 0.0033\n","PC46: Explained Variance = 0.0031\n","PC47: Explained Variance = 0.0029\n","PC48: Explained Variance = 0.0028\n","PC49: Explained Variance = 0.0026\n","PC50: Explained Variance = 0.0023\n","PC51: Explained Variance = 0.0022\n","PC52: Explained Variance = 0.0020\n","PC53: Explained Variance = 0.0020\n","PC54: Explained Variance = 0.0018\n","PC55: Explained Variance = 0.0017\n","PC56: Explained Variance = 0.0016\n","PC57: Explained Variance = 0.0015\n","PC58: Explained Variance = 0.0014\n","PC59: Explained Variance = 0.0013\n","PC60: Explained Variance = 0.0010\n","PC61: Explained Variance = 0.0008\n","PC62: Explained Variance = 0.0000\n","PC63: Explained Variance = 0.0000\n","PC64: Explained Variance = 0.0000\n"]}],"source":["# Get th explained variance ratio\n","explained_variance_ratio = pca.explained_variance_ratio_\n","\n","# Print the explained variance ratio for each principal component\n","for i, ev in enumerate(explained_variance_ratio):\n","  print(f\"PC{i+1}: Explained Variance = {ev:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"he_ncO_hHJTf"},"source":["### Exercise 3\n","\n","We can also evaluate how much total variance is captured as components are added incrementally. This can help us get a view of how many components are needed to capture a substantial proportion of the dataset's variance.\n","\n","Determine the cumulative variance ratio by summing the explained variance ratios of each principal component."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1716648436189,"user":{"displayName":"Paschal Ugwu","userId":"02920440952136523881"},"user_tz":-60},"id":"aZAhLfwQHJTf","outputId":"583c46b7-1410-4e8d-eb68-7dcd098de7ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["PC1: Cumulative Variance = 0.1203\n","PC2: Cumulative Variance = 0.2159\n","PC3: Cumulative Variance = 0.3004\n","PC4: Cumulative Variance = 0.3654\n","PC5: Cumulative Variance = 0.4140\n","PC6: Cumulative Variance = 0.4561\n","PC7: Cumulative Variance = 0.4955\n","PC8: Cumulative Variance = 0.5294\n","PC9: Cumulative Variance = 0.5594\n","PC10: Cumulative Variance = 0.5887\n","PC11: Cumulative Variance = 0.6166\n","PC12: Cumulative Variance = 0.6423\n","PC13: Cumulative Variance = 0.6651\n","PC14: Cumulative Variance = 0.6874\n","PC15: Cumulative Variance = 0.7090\n","PC16: Cumulative Variance = 0.7281\n","PC17: Cumulative Variance = 0.7459\n","PC18: Cumulative Variance = 0.7623\n","PC19: Cumulative Variance = 0.7782\n","PC20: Cumulative Variance = 0.7931\n","PC21: Cumulative Variance = 0.8066\n","PC22: Cumulative Variance = 0.8193\n","PC23: Cumulative Variance = 0.8310\n","PC24: Cumulative Variance = 0.8416\n","PC25: Cumulative Variance = 0.8513\n","PC26: Cumulative Variance = 0.8608\n","PC27: Cumulative Variance = 0.8694\n","PC28: Cumulative Variance = 0.8778\n","PC29: Cumulative Variance = 0.8857\n","PC30: Cumulative Variance = 0.8932\n","PC31: Cumulative Variance = 0.9005\n","PC32: Cumulative Variance = 0.9074\n","PC33: Cumulative Variance = 0.9139\n","PC34: Cumulative Variance = 0.9203\n","PC35: Cumulative Variance = 0.9262\n","PC36: Cumulative Variance = 0.9320\n","PC37: Cumulative Variance = 0.9372\n","PC38: Cumulative Variance = 0.9420\n","PC39: Cumulative Variance = 0.9465\n","PC40: Cumulative Variance = 0.9508\n","PC41: Cumulative Variance = 0.9548\n","PC42: Cumulative Variance = 0.9588\n","PC43: Cumulative Variance = 0.9624\n","PC44: Cumulative Variance = 0.9658\n","PC45: Cumulative Variance = 0.9691\n","PC46: Cumulative Variance = 0.9722\n","PC47: Cumulative Variance = 0.9751\n","PC48: Cumulative Variance = 0.9778\n","PC49: Cumulative Variance = 0.9804\n","PC50: Cumulative Variance = 0.9828\n","PC51: Cumulative Variance = 0.9849\n","PC52: Cumulative Variance = 0.9870\n","PC53: Cumulative Variance = 0.9889\n","PC54: Cumulative Variance = 0.9908\n","PC55: Cumulative Variance = 0.9924\n","PC56: Cumulative Variance = 0.9941\n","PC57: Cumulative Variance = 0.9955\n","PC58: Cumulative Variance = 0.9969\n","PC59: Cumulative Variance = 0.9981\n","PC60: Cumulative Variance = 0.9992\n","PC61: Cumulative Variance = 1.0000\n","PC62: Cumulative Variance = 1.0000\n","PC63: Cumulative Variance = 1.0000\n","PC64: Cumulative Variance = 1.0000\n"]}],"source":["# Calculate the cumulative variance ratio\n","cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n","\n","# Print the cumulative variance ratio for each principal component\n","for i, cv in enumerate(cumulative_variance_ratio):\n","  print(f\"PC{i+1}: Cumulative Variance = {cv:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"cjpKee-nHJTg"},"source":["### Exercise 4\n","\n","Based on the results from **Exercise 3**, determine how many components are needed to capture at least 85% of the total variance.\n","\n","Discuss the impact of this on subsequent analysis or modeling."]},{"cell_type":"markdown","metadata":{"id":"6a7AzCjkO62n"},"source":["### Discussing the impact of this on subsequent analysis or modeling\n","\n","The determination that 25 principal components are needed to capture at least 85% of the variance has significant implications for subsequent analysis or modeling:\n","\n","1. **Dimensionality Reduction**: Reducing the dimensionality from 64 original features to 25 principal components simplifies the dataset, making it more manageable and computationally efficient without losing much information.\n","\n","2. **Overfitting Reduction**: Using fewer components can help reduce the risk of overfitting, as the model will be less likely to learn noise from the data.\n","\n","3. **Model Performance**: While dimensionality reduction generally helps in improving model performance by focusing on the most significant features, it is essential to verify that the reduced set of features still captures the necessary patterns for accurate predictions.\n","\n","4. **Visualization**: Lower-dimensional data (e.g., 2 or 3 principal components) can be easily visualized, allowing for better understanding and interpretation of the dataset.\n","\n","5. **Computational Efficiency**: Models trained on a reduced feature set will require less computational power and memory, speeding up the training and prediction processes.\n","\n","Overall, determining the optimal number of principal components is a crucial step in balancing the trade-off between retaining essential information and simplifying the model."]},{"cell_type":"markdown","metadata":{"id":"EgzRklENHJTp"},"source":["<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n","<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n","</div>"]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"6b5ebbc2c6bde2831bc6c0426f75aca8137ccfc69d329557556ed73faee126ae"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
